{
   "top_projects":[

      {
         "title":"Brainy Noise",
         "imageUrls": [
            "https://static.wixstatic.com/media/07fea2_b9bdfb4e9dd54703b11bfb6845947954~mv2.png",
            "https://static.wixstatic.com/media/07fea2_8087ff7be5da4d618b96aa10ec2f0f93~mv2.png",
            "https://static.wixstatic.com/media/07fea2_3ce64c0661a54c26965175a98768002a~mv2.png"
         ],
         "description":"web prototype that allows to load magnetic resonances of the human brain and by using a machine learning model, obtains an answer with the identification of the noise level (presence or absence) of the images. During the development of the project, a model of Convolutional Neural Networks was developed. This is framed in the Artificial Intelligence area and its implementation was based on training, validation, testing and subsequent deployment. At the end, the applied model is the one that allows the identification of the noise level for each one of the magnetic resonances of the human brain.\nAdditionally, a file is generated with the result of the classification that is compatible with the information handled in the research area of the Faculty of Medicine of the Pontificia Universidad Javeriana and the Hospital San Ignacio. This can be downloaded once the result is obtained and the user can view it in the web prototype.",
         "links":[
            {"url": "https://github.com/Proyecto-de-Grado-Brainy-Noise","name": "Repositories"}
         ]
      },

      {
         "title":"Carvi",
         "imageUrls": [
            "https://static.wixstatic.com/media/07fea2_881e63a05605400490285c80606bf2a0~mv2.png",
            "https://static.wixstatic.com/media/07fea2_a369cf7d14784c43b4bb459e627c7708~mv2.png",
            "https://static.wixstatic.com/media/07fea2_009d561c20944d64aa6e1fc823b8d40f~mv2.png"
         ],
         "description":"CarVi is a mobile application that offers the ability to capture photos of vehicles and obtain relevant information about them. The app uses two models to achieve this. First, it uses a model called ResNet50, which is a pre-trained convolutional neural network. However, instead of using it directly, the model is fine-tuned to specifically adapt it for the purpose of vehicle recognition. Fine-tuning involves retraining the model using a custom dataset, allowing model weights and features to be tuned to improve its accuracy in the vehicle recognition task. Second, CarVi uses an approach called the Spatial Attention Module (SAM) developed by Meta. SAM is used to remove the \"noise\" from the captured image of the vehicle, that is, its background and therefore only capture the vehicle. The spatial attention module helps to focus the model's attention on the most important regions of the image, which helps improve the quality and clarity of the information obtained from the vehicle.",
         "links":[
            {"url": "https://github.com/Sebas102507/carvi_app","name": "Frontend Repository"},
            {"url": "https://github.com/Sebas102507/Carvi_Deep_Learning_Mobile_App/tree/main","name": "Backend Repository"}
         ]
      },

      {
         "title":"Litnine Cannabis",
         "imageUrls": [
            "https://static.wixstatic.com/media/07fea2_51d5faf1e923418b9a563821b6a0ee3e~mv2.png",
            "https://static.wixstatic.com/media/07fea2_27169f5ef87c4baca0a66854a247db75~mv2.png",
            "https://static.wixstatic.com/media/07fea2_8283d12eb2e7466fa35cebe10249506d~mv2.png"
         ],
         "description":"Litnine and Litnine Tiendas are two mobile applications that offer a marketplace specialized in the cannabis sector in Colombia. These applications have as their main objective to bring together in one place cannabis shops and consumers of medical and recreational cannabis. Litnine is the platform that connects consumers with cannabis shops. It provides users with a wide selection of cannabis shops, where they can explore different products, such as cannabis varieties, medicinal products, accessories, among others. Consumers can make purchases directly through the application and have the convenience of receiving the products at home. On the other hand, Litnine Tiendas is the platform designed for cannabis stores in Colombia. It offers businesses an online sales platform to promote their products and reach a broader customer base. Stores can display their inventory, describe their products, and manage transactions with consumers through the app. These applications seek to provide a safe and reliable space for cannabis consumers, providing clear information about the products and ensuring that the stores comply with the legal regulations established in Colombia. In addition, they offer a convenient and accessible experience for consumers who want to purchase products related to medical and recreational cannabis.",
         "links":[
            {"url": "https://www.litnine.com","name": "Web Page"}
         ]
      },

      {
         "title":"MeteoNet",
         "imageUrls": [
            "https://static.wixstatic.com/media/07fea2_e113a392d62c45c98d54f0e5f886e40b~mv2.png",
            "https://static.wixstatic.com/media/07fea2_17accfd352ec4454af7d7e1daaf3258f~mv2.png",
            "https://static.wixstatic.com/media/07fea2_2d7c9f24a85f45298d2d52295fadf086~mv2.png"
         ],
         "description":"MeteoNet is a data set published by the French meteorological service METEO FRANCE for the community to propose analyzes and models using climate data.\nSome of the data available in MeteoNet are the historical meteorological observations of sensors that measure temperature, humidity, pressure, wind in different stations located throughout the French territory, given the above, a meteorological station was chosen to analyze and through the use of networks recurrent neural pathways create a predictive model of temperature and precipitation at the weather station.",
         "links":[
            {"url": "https://github.com/Sebas102507/MeteoNetForecasting/tree/main","name": "Repository"}
         ]
      },

      {
         "title":"Music Genre Classifier",
         "imageUrls": [
            "https://firebasestorage.googleapis.com/v0/b/mywebpage-f159c.appspot.com/o/MusicGenreClassifier%2FScreenshot%202023-06-20%20at%202.38.31%20PM.png?alt=media&token=38b6c6a7-4d05-43b6-beca-f1a87f79d191",
            "https://firebasestorage.googleapis.com/v0/b/mywebpage-f159c.appspot.com/o/MusicGenreClassifier%2FScreenshot%202023-06-20%20at%202.38.48%20PM.png?alt=media&token=0b4617f2-dc88-4a74-b01a-2e416b0b0357",
            "https://firebasestorage.googleapis.com/v0/b/mywebpage-f159c.appspot.com/o/MusicGenreClassifier%2FScreenshot%202023-06-20%20at%202.39.07%20PM.png?alt=media&token=0e7de869-b0d5-484f-bb78-af35e7c9d937"
         ],
         "description":"The objective of the application is to correctly predict different 30-second audios provided by the user. The training of the models is based on the GTZAN music dataset.\nThe System has the following functional requirements, which in turn are presented as its functionalities.\n1) Make a prediction: The System must allow the user to load a .wav audio file no longer than 30 seconds. The System must then predict the musical genre of said audio and pass the calculated answer to the user.\n2) Obtain the results: The System must allow obtaining all the results calculated through the model. That is, all computed responses to requests to make a prediction.\n3) Access to the audios: The System must have a persistent storage of the audio files uploaded by the users. This allows you to compare the audio heard with the prediction made.\n4) Modify the model: The system must allow the system administrator to easily change the model trained to make the predictions. However, there is no need to train the model directly within the hardware components of the System. It can be trained externally and then brought into the System.",
         "links":[
            {"url": "https://github.com/Sebas102507/music_gender_app_classifier_with_NN","name": "Repository"}
         ]
      },

      {
         "title":"Rubik's Cube Deep Q-Network",
         "imageUrls": [
            "https://static.wixstatic.com/media/07fea2_dc563444a20c458692315d0d932d0733~mv2.png",
            "https://static.wixstatic.com/media/07fea2_f59ecc69fdf54217b7f769141358fb0d~mv2.png",
            "https://static.wixstatic.com/media/07fea2_65701c439c664d898364726e416bab82~mv2.png"
         ],
         "description":"The project consists of developing an artificial intelligence model that is capable of solving the famous Rubik's cube puzzle automatically. To achieve this, a technique known as Deep Q-Networks (DNQ) is used.\nThe main idea is to train an artificial intelligence agent using the reinforcement learning technique. The agent is challenged to solve the Rubik's cube and learns to make decisions based on his current state and the actions available to move the faces of the cube. Using the DNQ technique, the agent learns to select the best actions in each state to get closer to an optimal solution.\nModel training is done through a combination of exploration and exploitation. The agent explores different movements and actions to discover new strategies and learn from the feedback received. At the same time, the agent also exploits prior knowledge and learned experiences to improve its performance.\nDuring training, the model is faced with different configurations of the Rubik's Cube and is given a positive reward when it progresses towards the solution and a negative reward when it moves away from the solution. As the agent continues to train and adjust his strategy, it is expected that he will be able to solve the Rubik's Cube more efficiently and in fewer moves.\nOnce the model is trained, it can be used to solve the Rubik's Cube automatically. The agent evaluates the current state of the cube and selects the optimal actions to reach a solution. The final result is a model capable of solving the Rubik's cube autonomously and efficiently.",
         "links":[
            {"url": "https://github.com/Sebas102507/RubikCubeDQN","name": "Repository"}
         ]
      },

      {
         "title":"Sign Language AI Classifier",
         "imageUrls": [
            "https://static.wixstatic.com/media/07fea2_81f2cf2e20a0492eb46a262e6a461b5f~mv2.png",
            "https://static.wixstatic.com/media/07fea2_08cf77e09f8b43f7a38fae6454bb86ac~mv2.png",
            "https://static.wixstatic.com/media/07fea2_d6b7354305184031bbf61b8b5ee18bf1~mv2.png"
         ],
         "description":"The project uses the \"sign-language-mnist\" dataset, which contains images of 25 signs of sign language, each with its respective label. In this project three approaches were implemented using convolutional networks to classify signs of sign language.\nThe first approach is to train a convolutional network from scratch, which involves designing and training the neural network architecture without using transfer learning techniques. The convolutional network learns directly from the images in the dataset and adjusts for the specific characteristics of signs in sign language.\nIn the second approach, transfer learning is used, which involves leveraging a pre-trained neural network on a different data set. A pre-trained convolutional network, such as VGG16 or ResNet, is selected, and the latter network components are adjusted to fit the sign language dataset. This allows you to take advantage of the prior knowledge of the pre-trained network and speed up the training process.\nIn the third approach, transfer learning is used with the MobileNet V2 convolutional network. MobileNet V2 is an efficient architecture designed for computer vision tasks on mobile devices. By leveraging pre-trained MobileNet V2 on a large dataset, it can be used as a solid foundation for classifying the signs of sign language in this project.",
         "links":[
            {"url": "https://github.com/Sebas102507/SignLanguageAiClassifier/tree/main","name": "Repository"}
         ]
      },

      {
         "title":"Stock LSTM Forecasting",
         "imageUrls": [
            "https://static.wixstatic.com/media/07fea2_4c235c10da6743deb13c104f524179e4~mv2.png",
            "https://static.wixstatic.com/media/07fea2_47940a03eb424699a75d9b022512102e~mv2.png",
            "https://static.wixstatic.com/media/07fea2_b74593c918544df0abb25a83e5d151d9~mv2.png"
         ],
         "description":"The project consists of using a recurrent neural network LSTM (Long Short-Term Memory) to predict the price of a company's shares, in this specific case, The Home Depot (HD) company is used. To do this, a data engineering process is applied to obtain the relevant data necessary for model training.\nThe first step is to collect historical data for The Home Depot stock price, as well as data for the Annual Current Ratio, PE Ratio, Debt Equity Ratio, Turnover, ROE, PS Ratio, CPI (Consumer Price Index) and Interest rates. This data is obtained from trusted sources, such as financial databases or online data services.\nOnce the LSTM model is trained, the prediction of the future stock price is performed. Historical data and related characteristics such as the Annual Current Ratio, PE Ratio, Debt Equity Ratio, Turnover, ROE, PS Ratio, CPI, and interest rates are used to predict The Home Depot's stock price in a future period.\nFinally, the performance of the model is evaluated using appropriate metrics, such as the mean square error (MSE) or the coefficient of determination (R2).",
         "links":[
            {"url": "https://github.com/Sebas102507/LSTMStockForecasting/tree/main","name": "Repository"}
         ]
      },

      {
         "title":"LSTM Simpson's Chapter Script Generator",
         "imageUrls": [
            "https://static.wixstatic.com/media/07fea2_a0ae6adc782c47898a91ceff8982b195~mv2.png",
            "https://static.wixstatic.com/media/07fea2_7c0d1513cbbe40e084a5a683df1226f6~mv2.png",
            "https://static.wixstatic.com/media/07fea2_c6757232dec24ece9355fbab31fb0479~mv2.png"
         ],
         "description":"The objective of this project is to utilize Long Short-Term Memory (LSTM), a type of recurrent neural network (RNN), to generate new chapters for the popular animated TV show \"The Simpsons.\" By leveraging a comprehensive database containing the transcripts of all existing \"Simpsons\" chapters, the LSTM model will learn the patterns, language, and comedic style of the show, allowing it to generate original content that captures the essence of the beloved series.\nThe project will involve several key steps. First, a dataset will be created by compiling the transcripts of all \"Simpsons\" chapters, ensuring that it is clean and well-structured for training the LSTM model. The dataset will serve as the foundation for the model's language learning and comprehension.\nNext, the LSTM architecture will be implemented and trained on the dataset. LSTM networks are specifically designed to capture long-term dependencies and temporal dynamics, making them well-suited for tasks such as language generation. The model will be trained to predict the next word or phrase given a sequence of preceding words from the transcripts.\nOnce the LSTM model has been trained, it will be capable of generating new chapters based on user prompts or random seed inputs. By providing an initial sentence or phrase, the model will utilize its learned knowledge of \"The Simpsons\" language and style to construct coherent and entertaining narratives. The generated chapters will emulate the humor, character dynamics, and storytelling elements that have made the show so popular over the years.",
         "links":[
            {"url": "https://github.com/Sebas102507/RNNSimpsonsChapterGenerator/tree/main","name": "Repository"}
         ]
      }

   ]
}
